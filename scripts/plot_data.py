#!/usr/bin/env python3
import argparse
import csv
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import glob

# used for plt.savefig
# font = {'family' : 'STIXGeneral',
#         'weight' : 'normal',
#         'size'   : 35}
# plt.rc('font', **font)

plt.rcParams['mathtext.fontset'] = 'stix'
plt.rcParams['font.family'] = 'STIXGeneral'
plt.rcParams.update({'font.size': 22})

def plot_entropy(df):
    # get current axis
    axes = plt.gca()
    df.plot(kind='line', x='frame', y='Pose_entropy', ax=axes)
    mean = np.nanmean(df.Pose_entropy)
    plt.axhline(y=mean, color='red', linestyle='--', label='mean')
    var = np.nanvar(df.Pose_entropy)
    std = np.sqrt(var)
    print("--------------")
    print("Mean: ", mean)
    print("Variance: ", var)
    print("Std: ", std)
    print("--------------")
    plt.fill_between(axes.get_xlim(),mean+std,mean-std, color='red', alpha=.5)
    plt.xlabel('Frames')
    plt.ylabel('Pose entropy')
    plt.show()

def compute_pose_correlation(df, error_array):
    entropy_array = df.Pose_entropy.to_numpy()
    correlation = np.corrcoef(entropy_array, error_array)
    print("Correlation: ", correlation)
    plt.scatter(entropy_array, error_array)
    plt.title('RPE and entropy correlation')
    plt.xlabel('Entropy')
    plt.ylabel('RPE')
    plt.show()

def concatenate_data(df, error_array, column_name, output):
    if 'mean_time' in df.columns:
        df.drop(columns=['mean_time'], axis=1, inplace=True)
    
    if column_name not in df.columns:
        df.dropna(how='all', axis=1, inplace=True)
        if column_name == 'ape':
            df[column_name] = manipulate_ape(error_array).tolist()
            df.to_csv(output, encoding='utf-8', index=False)
        else:
            df[column_name] = error_array.tolist()
            df.to_csv(output, encoding='utf-8', index=False)

def compute_data_correlation(df, output, range, fields):
    if range:
        df = filter_df_by_range(df, 'frame', range[0], range[1])
    if 'frame' in df.columns:
        df.drop(columns=['frame'], axis=1, inplace=True)
    if fields:
        df = df.loc[:, fields]
    corrM = df.corr()
    fig, ax = plt.subplots(figsize=(30,30))
    sns.heatmap(corrM, annot=True, fmt='.4f', 
    cmap=plt.get_cmap('coolwarm'), cbar=False, ax=ax)
    ax.set_yticklabels(ax.get_yticklabels(), rotation="horizontal")
    if output:
        plt.savefig(output, bbox_inches='tight', pad_inches=2.0)
    else:
        plt.show()

def plot_data(df, fields, range_values, normalize_data, labels):
    vectors = {}
    for field in fields:
        data = []
        for index in range(range_values[0], range_values[1]+1):
            values = df.loc[df['frame']==index, field].values
            data.append(values[0])
        vectors[field] = data
    
    keys = list(vectors.keys())
    key1 = keys[0]
    data1 = vectors[key1]
    key2 = keys[1]
    data2 = vectors[key2]

    if normalize_data:
        data1 = normalize_array(data1)
        data2 = normalize_array(data2)

    fig, ax1 = plt.subplots()
    x = list(range(range_values[0], range_values[1]+1))

    color = 'tab:red'
    ax1.set_xlabel('Frames')
    ax1.plot(x, data1, color=color)
    ax1.tick_params(axis='y', color=color)

    ax2 = ax1.twinx()
    
    color = 'tab:blue'
    ax2.plot(x, data2, color=color)
    ax2.tick_params(axis='y', color=color)

    if labels:
        ax1.set_ylabel(labels[0], color=color)
        ax2.set_ylabel(labels[1], color=color)
    else:
        ax1.set_ylabel(key1, color=color)
        ax2.set_ylabel(key2, color=color)
         

    fig.tight_layout()
    # plt.legend()
    plt.show()

def filter_df_by_range(df, column_name, min_val, max_val):
    filtered_df = df[(df[column_name] >= min_val) & (df[column_name] <= max_val)]
    return filtered_df

def manipulate_ape(array):
    rate_of_increase = np.diff(array)
    return rate_of_increase
    
def normalize_array(arr):
    min_val = np.min(arr)
    max_val = np.max(arr)
    return (arr - min_val) / (max_val - min_val)


def plot_velocity(files):
    files.sort()
    velocities = []
    for file in files:
        with open(file) as f:
            line = f.readlines()
            list = line[0].split(" ")
            velocities.append(float(list[8]))
    plt.plot(velocities)
    plt.xlabel("Index")
    plt.ylabel("Velocity (m/s)")
    plt.show()

parser = argparse.ArgumentParser(
    description='Plot data from csv file generated by the KLTVO library.')

parser.add_argument('--file', '-f',
                    help='CSV file with the data provided by kltvo')

parser.add_argument('--error_file',
                    help='File containing the vector of errors computed by evo')

parser.add_argument('--plot_entropy',
                    action="store_true",
                    help='Plot pose entropy')

parser.add_argument('--compute_pose_correlation',
                    action="store_true",
                    help='Compute correlation between provided pose entropy and provided error array')

parser.add_argument('--compute_df_correlation',
                    action="store_true",
                    help='Compute correlation between all data')

parser.add_argument('--output', '-o',
                    help='Output directory')

parser.add_argument('--fuse_data',
                    action="store_true",
                    help='Fuse np array with worksheet')

parser.add_argument('--column_name',
                    help='name of the new column to be created')

parser.add_argument('--plot_multi_data',
                    action="store_true",
                    help='Plot multiple defined data in the same graph')

parser.add_argument('--fields',
                    nargs='+',
                    help='List of the fields to be analyzed')
parser.add_argument('--range',
                    nargs='+',
                    type=int,
                    help='Range of data to be analyzed (e.g. frame index)')
parser.add_argument('--normalize_data',
                    action="store_true",
                    help='Set this argument if you want to normalize the data between 0 and 1')
parser.add_argument('--dir',
                    help='Directory containing files to be processed')

parser.add_argument('--plot_kitti_velocity',
                    action="store_true",
                    help='Plot velocities of a given sequence from KITTI dataset')
parser.add_argument('--labels',
                    nargs='+',
                    help='List of labels for ploting')

args = parser.parse_args()

if args.file is not None:
    # if(args.file.endswith('.csv')):
    fh = open(args.file)

    csv_reader = csv.reader(fh)
    csv_header = next(csv_reader)
    fh.close()
    df = pd.read_csv(args.file, header=None, skiprows=1, names=csv_header)

    # if(args.file.endswith('.txt')):

if args.error_file is not None:
    error_array = np.load(args.error_file)

if(args.plot_entropy):
    plot_entropy(df)

if(args.compute_pose_correlation):
    compute_pose_correlation(df,error_array, args.all)

if(args.fuse_data):
    if args.output is not None:
        concatenate_data(df, error_array, args.column_name, args.output)
    else:
        concatenate_data(df, error_array, args.column_name, args.file)

if(args.compute_df_correlation):
    compute_data_correlation(df, args.output, args.range, args.fields)

if(args.plot_multi_data):
    plot_data(df, args.fields, args.range, args.normalize_data, args.labels)

if(args.plot_kitti_velocity):
    if args.dir:
        txt_files = glob.glob(args.dir+"*.txt")
        plot_velocity(txt_files)